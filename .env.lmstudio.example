# LM Studio provider preset (OpenAI-compatible local API)
AGENT_PROVIDER=lmstudio
# Put LM Studio model name loaded in the app
AGENT_MODEL=openai/gpt-oss-20b

# Behavior
AGENT_APPROVAL=on-request
AGENT_SAFE_MODE=extended
AGENT_MAX_STEPS=12
AGENT_SERVE_PORT=8080
AGENT_STREAM=true  # stream deltas to CLI/Web UI

# Paths
# AGENT_WORKSPACE=/home/ubuntu/agent-workspace
AGENT_CONFIG_DIR=.agentic
AGENT_LOG_DIR=logs

# Timeouts
AGENT_REQUEST_TIMEOUT=120
AGENT_TOOL_TIMEOUT=180

# Reasoning
# Enable high-effort reasoning summaries for models that support it
AGENT_REASONING=on    # off|on|auto
AGENT_REASONING_EFFORT=high  # low|medium|high

# LM Studio endpoint (OpenAI-compatible local server)
# Enable "Local Server (OpenAI API)" in LM Studio first.
LMSTUDIO_BASE_URL=http://localhost:1234
